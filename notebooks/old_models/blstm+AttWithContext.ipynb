{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk1/home/sum5275/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/disk1/home/sum5275/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Flatten, MaxPooling2D, Conv2D, Reshape, concatenate,\\\n",
    "Embedding, BatchNormalization, Activation, Dropout, Bidirectional, LSTM, GRU\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from AttentionWithContext import AttentionWithContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['toxic', 'severe_toxic',\n",
    "           'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    pattern = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "    return pattern.sub(r' \\1 ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = data['comment_text'].fillna('UNK').apply(clean).values\n",
    "y = data[classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments, val_comments, y_train, y_val = train_test_split(comments, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_SEQUENCE_LENGTH = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(train_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_comments)\n",
    "val_sequences   = tokenizer.texts_to_sequences(val_comments)\n",
    "X_train         = pad_sequences(train_sequences, maxlen = MAX_SEQUENCE_LENGTH)\n",
    "X_val           = pad_sequences(val_sequences, maxlen = MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 178237 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.840B.300d.txt  glove.840B.300d.zip\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error reading word .\n",
      "error reading word at\n",
      "error reading word .\n",
      "error reading word to\n",
      "error reading word .\n",
      "error reading word .\n",
      "error reading word email\n",
      "error reading word or\n",
      "error reading word contact\n",
      "error reading word Email\n",
      "error reading word on\n",
      "error reading word At\n",
      "error reading word by\n",
      "error reading word in\n",
      "error reading word emailing\n",
      "error reading word Contact\n",
      "error reading word at\n",
      "error reading word •\n",
      "error reading word at\n",
      "error reading word is\n",
      "Found 2195884 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('../embeddings/glove.840B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    try:\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    except:\n",
    "        print(\"error reading word\", word)\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix\n",
      "Null word embeddings: 814\n"
     ]
    }
   ],
   "source": [
    "print('Preparing embedding matrix')\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "x = Embedding(nb_words, EMBEDDING_DIM, weights=[embedding_matrix], trainable=False)(comment_input)\n",
    "x = Bidirectional(LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = AttentionWithContext()(x)\n",
    "\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "predictions = Dense(6, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(comment_input, predictions)\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 150, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 150, 200)          320800    \n",
      "_________________________________________________________________\n",
      "attention_with_context_3 (At (None, 200)               40400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 6,382,306\n",
      "Trainable params: 382,106\n",
      "Non-trainable params: 6,000,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_ckpt = ModelCheckpoint(filepath='../models/blstm_att_context.h5', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3)\n",
    "callbacks = [model_ckpt, reduce_lr, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/10\n",
      "143613/143613 [==============================] - 251s 2ms/step - loss: 0.1326 - acc: 0.9695 - val_loss: 0.0602 - val_acc: 0.9805\n",
      "Epoch 2/10\n",
      "143613/143613 [==============================] - 249s 2ms/step - loss: 0.0501 - acc: 0.9816 - val_loss: 0.0461 - val_acc: 0.9832\n",
      "Epoch 3/10\n",
      "143613/143613 [==============================] - 277s 2ms/step - loss: 0.0467 - acc: 0.9826 - val_loss: 0.0454 - val_acc: 0.9826\n",
      "Epoch 4/10\n",
      "143613/143613 [==============================] - 386s 3ms/step - loss: 0.0443 - acc: 0.9835 - val_loss: 0.0452 - val_acc: 0.9834\n",
      "Epoch 5/10\n",
      "143613/143613 [==============================] - 314s 2ms/step - loss: 0.0429 - acc: 0.9838 - val_loss: 0.0469 - val_acc: 0.9827\n",
      "Epoch 6/10\n",
      "143613/143613 [==============================] - 247s 2ms/step - loss: 0.0412 - acc: 0.9843 - val_loss: 0.0447 - val_acc: 0.9840\n",
      "Epoch 7/10\n",
      "143613/143613 [==============================] - 257s 2ms/step - loss: 0.0398 - acc: 0.9846 - val_loss: 0.0430 - val_acc: 0.9839\n",
      "Epoch 8/10\n",
      "143613/143613 [==============================] - 256s 2ms/step - loss: 0.0385 - acc: 0.9851 - val_loss: 0.0473 - val_acc: 0.9828\n",
      "Epoch 9/10\n",
      "143613/143613 [==============================] - 249s 2ms/step - loss: 0.0372 - acc: 0.9854 - val_loss: 0.0433 - val_acc: 0.9841\n",
      "Epoch 10/10\n",
      "143613/143613 [==============================] - 248s 2ms/step - loss: 0.0359 - acc: 0.9859 - val_loss: 0.0429 - val_acc: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2280375208>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=256, epochs=10, callbacks=callbacks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../models/blstm_att_context.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15958/15958 [==============================] - 50s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = model.predict(X_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15958, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09389108551392919"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_val[:, 0], y_pred_val[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val[:, 0] = y_pred_val[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic           log_loss: 0.09 auc: 0.98 acc: 0.97\n",
      "\n",
      "[[14245   229]\n",
      " [  293  1191]]\n",
      "\n",
      "severe_toxic    log_loss: 0.02 auc: 0.98 acc: 0.99\n",
      "\n",
      "[[15780    26]\n",
      " [  103    49]]\n",
      "\n",
      "obscene         log_loss: 0.05 auc: 0.99 acc: 0.98\n",
      "\n",
      "[[14995   146]\n",
      " [  119   698]]\n",
      "\n",
      "threat          log_loss: 0.01 auc: 0.97 acc: 1.00\n",
      "\n",
      "[[15904     1]\n",
      " [   48     5]]\n",
      "\n",
      "insult          log_loss: 0.06 auc: 0.99 acc: 0.97\n",
      "\n",
      "[[14962   234]\n",
      " [  165   597]]\n",
      "\n",
      "identity_hate   log_loss: 0.02 auc: 0.98 acc: 0.99\n",
      "\n",
      "[[15787    16]\n",
      " [   98    57]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.DataFrame()\n",
    "for i, col in enumerate(classes):\n",
    "    loss = log_loss(y_val[:, i], y_pred_val[:, i])\n",
    "    auc = roc_auc_score(y_val[:, i], y_pred_val[:, i])\n",
    "    acc = accuracy_score(y_val[:, i], (y_pred_val[:, i] > .5).astype(int))\n",
    "    val_df = val_df.append({'class': col, 'auc': auc, 'loss': loss, 'acc': acc}, ignore_index=True)\n",
    "    print('{:15} log_loss: {:.2f} auc: {:.2f} acc: {:.2f}'.format(col, loss, auc, acc))\n",
    "    print()\n",
    "    print(confusion_matrix(y_val[:, i], (y_pred_val[:, i] > .5).astype(int)))\n",
    "    print()\n",
    "val_df = val_df.set_index('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc     0.984564\n",
       "auc     0.980920\n",
       "loss    0.042378\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comments = test['comment_text'].fillna('UNK')\n",
    "test_sequences = tokenizer.texts_to_sequences(test_comments)\n",
    "X_test = pad_sequences(test_sequences, maxlen = MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../models/blstm_att_context.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 457s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.iloc[:, 1:] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../submissions/blstm_att_context.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.998951</td>\n",
       "      <td>3.181610e-01</td>\n",
       "      <td>0.962042</td>\n",
       "      <td>1.398098e-02</td>\n",
       "      <td>0.926105</td>\n",
       "      <td>5.011047e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>3.353382e-07</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.450277e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.809840e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>9.019499e-06</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>2.879248e-06</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>1.005919e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>1.675939e-06</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>2.664927e-06</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.957815e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.013740</td>\n",
       "      <td>1.591392e-04</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>1.108757e-04</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>1.271297e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene        threat    insult  \\\n",
       "0  00001cee341fdb12  0.998951  3.181610e-01  0.962042  1.398098e-02  0.926105   \n",
       "1  0000247867823ef7  0.000131  3.353382e-07  0.000006  3.450277e-08  0.000006   \n",
       "2  00013b17ad220c46  0.000410  9.019499e-06  0.000250  2.879248e-06  0.000231   \n",
       "3  00017563c3f7919a  0.000140  1.675939e-06  0.000038  2.664927e-06  0.000043   \n",
       "4  00017695ad8997eb  0.013740  1.591392e-04  0.004634  1.108757e-04  0.002463   \n",
       "\n",
       "   identity_hate  \n",
       "0   5.011047e-01  \n",
       "1   3.809840e-07  \n",
       "2   1.005919e-05  \n",
       "3   1.957815e-06  \n",
       "4   1.271297e-04  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../submissions/blstm_att_context.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
