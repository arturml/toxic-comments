{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk1/home/sum5275/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/disk1/home/sum5275/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, GRU, Embedding, Dropout, Activation, BatchNormalization, AveragePooling1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from Attention import *\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22256635</td>\n",
       "      <td>Nonsense?  kiss off, geek. what I said is true...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27450690</td>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54037174</td>\n",
       "      <td>\"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77493077</td>\n",
       "      <td>Asking some his nationality is a Racial offenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79357270</td>\n",
       "      <td>The reader here is not going by my say so for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                       comment_text  toxic  \\\n",
       "0  22256635  Nonsense?  kiss off, geek. what I said is true...      1   \n",
       "1  27450690  \"\\n\\n Please do not vandalize pages, as you di...      0   \n",
       "2  54037174  \"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...      0   \n",
       "3  77493077  Asking some his nationality is a Racial offenc...      0   \n",
       "4  79357270  The reader here is not going by my say so for ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = data.columns[2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments = data['comment_text'].fillna('UNK')\n",
    "labels = data.loc[:, classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 200000\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_SEQUENCE_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(train_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_comments)\n",
    "X_train = pad_sequences(train_sequences, maxlen = MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data[classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153188 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.840B.300d.txt  glove.840B.300d.zip\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error reading word .\n",
      "error reading word at\n",
      "error reading word .\n",
      "error reading word to\n",
      "error reading word .\n",
      "error reading word .\n",
      "error reading word email\n",
      "error reading word or\n",
      "error reading word contact\n",
      "error reading word Email\n",
      "error reading word on\n",
      "error reading word At\n",
      "error reading word by\n",
      "error reading word in\n",
      "error reading word emailing\n",
      "error reading word Contact\n",
      "error reading word at\n",
      "error reading word â€¢\n",
      "error reading word at\n",
      "error reading word is\n",
      "Found 2195884 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('../embeddings/glove.840B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    try:\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    except:\n",
    "        print(\"error reading word\", word)\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix\n",
      "Null word embeddings: 68661\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "print('Preparing embedding matrix')\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153189, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(nb_words, EMBEDDING_DIM, weights=[embedding_matrix], trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "x = embedding_layer(comment_input)\n",
    "x = Bidirectional(LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = AveragePooling1D(strides=2)(x)\n",
    "x = Bidirectional(LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = AveragePooling1D(strides=2)(x)\n",
    "x = Bidirectional(LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = AveragePooling1D(strides=2)(x)\n",
    "x = Attention()(x)\n",
    "x = Dense(200, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(6, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(comment_input, predictions)\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          45956700  \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 100, 200)          320800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 50, 200)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 50, 200)           240800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_5 (Average (None, 25, 200)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 25, 200)           240800    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_6 (Average (None, 12, 200)           0         \n",
      "_________________________________________________________________\n",
      "attention_2 (Attention)      (None, 200)               212       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 46,810,868\n",
      "Trainable params: 853,668\n",
      "Non-trainable params: 45,957,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_ckpt = ModelCheckpoint(filepath='../models/deep_bstlm_attention.h5', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5)\n",
    "callbacks = [early_stopping, model_ckpt, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86265 samples, validate on 9586 samples\n",
      "Epoch 1/50\n",
      "86265/86265 [==============================] - 179s 2ms/step - loss: 0.2966 - acc: 0.9096 - val_loss: 0.0729 - val_acc: 0.9794\n",
      "Epoch 2/50\n",
      "86265/86265 [==============================] - 174s 2ms/step - loss: 0.0670 - acc: 0.9787 - val_loss: 0.0508 - val_acc: 0.9819\n",
      "Epoch 3/50\n",
      "86265/86265 [==============================] - 173s 2ms/step - loss: 0.0545 - acc: 0.9804 - val_loss: 0.0508 - val_acc: 0.9818\n",
      "Epoch 4/50\n",
      "86265/86265 [==============================] - 172s 2ms/step - loss: 0.0497 - acc: 0.9815 - val_loss: 0.0509 - val_acc: 0.9809\n",
      "Epoch 5/50\n",
      "86265/86265 [==============================] - 173s 2ms/step - loss: 0.0471 - acc: 0.9824 - val_loss: 0.0470 - val_acc: 0.9829\n",
      "Epoch 6/50\n",
      "86265/86265 [==============================] - 173s 2ms/step - loss: 0.0453 - acc: 0.9830 - val_loss: 0.0460 - val_acc: 0.9827\n",
      "Epoch 7/50\n",
      "86265/86265 [==============================] - 173s 2ms/step - loss: 0.0437 - acc: 0.9835 - val_loss: 0.0458 - val_acc: 0.9824\n",
      "Epoch 8/50\n",
      "86265/86265 [==============================] - 171s 2ms/step - loss: 0.0423 - acc: 0.9839 - val_loss: 0.0467 - val_acc: 0.9827\n",
      "Epoch 9/50\n",
      "86265/86265 [==============================] - 173s 2ms/step - loss: 0.0408 - acc: 0.9844 - val_loss: 0.0484 - val_acc: 0.9825\n",
      "Epoch 10/50\n",
      "86265/86265 [==============================] - 174s 2ms/step - loss: 0.0394 - acc: 0.9848 - val_loss: 0.0483 - val_acc: 0.9832\n",
      "Epoch 11/50\n",
      "86265/86265 [==============================] - 173s 2ms/step - loss: 0.0378 - acc: 0.9853 - val_loss: 0.0482 - val_acc: 0.9830\n",
      "Epoch 12/50\n",
      "86265/86265 [==============================] - 172s 2ms/step - loss: 0.0367 - acc: 0.9858 - val_loss: 0.0486 - val_acc: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f7a136710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=256, epochs=50, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comments = test['comment_text'].fillna('UNK')\n",
    "test_sequences = tokenizer.texts_to_sequences(test_comments)\n",
    "X_test = pad_sequences(test_sequences, maxlen = MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../models/deep_bstlm_attention.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.iloc[:, 1:] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../submissions/deep_bstlm_attention.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('bstlm_attention.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6044863</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>4.169984e-06</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6102620</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>7.169110e-07</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14563293</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>4.495609e-07</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21086297</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>5.858633e-06</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22982444</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>6.175662e-06</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     toxic  severe_toxic   obscene        threat    insult  \\\n",
       "0   6044863  0.000402      0.000025  0.000044  4.169984e-06  0.000041   \n",
       "1   6102620  0.000703      0.000010  0.000268  7.169110e-07  0.000042   \n",
       "2  14563293  0.000136      0.000005  0.000077  4.495609e-07  0.000010   \n",
       "3  21086297  0.001266      0.000038  0.000113  5.858633e-06  0.000108   \n",
       "4  22982444  0.000594      0.000033  0.000063  6.175662e-06  0.000057   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.000004  \n",
       "1       0.000008  \n",
       "2       0.000003  \n",
       "3       0.000009  \n",
       "4       0.000006  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../submissions/deep_bstlm_attention.csv').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
